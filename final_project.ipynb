{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721a8539",
   "metadata": {},
   "source": [
    "# Key Word- Spotting Smart-Home System: ELECT_ENG 475: Machine Learning: Foundations, Applications, and Algorithms Project Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eed7e6",
   "metadata": {},
   "source": [
    "**Eric Oliveira, Justin Ansell, Vivek Matta**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76bf85",
   "metadata": {},
   "source": [
    "**Important Notes**: \n",
    "\n",
    "1) This 'requirements.txt' was generated from a working conda environment on an Apple Silicon MacBook running macOS, using Miniforge3 (conda/Anaconda-compatible) as the Python distribution and Jupyter/IPython for development. The package versions reflect that specific setup and were tested in that environment; users on other platforms may need to adjust versions or install platform-specific builds accordingly.**\n",
    "\n",
    " 2) This notebook is known to support python versions up to 3.11.14 . It will likely not work with a version >3.12\n",
    "\n",
    " 3) The chosen kernel for this notebook must have 'ipykernel' to be able to run a .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203349e",
   "metadata": {},
   "source": [
    "Additional code / YouTube video:\n",
    "\n",
    "- [All the file processing code (GitHub)](https://github.com/Eclo19/smart-home-kws)\n",
    "- [Model training (Google Colab)](https://colab.research.google.com/drive/1zg0SPHg8Gk4uLPPREuo5_4F8gLJBUEz0?authuser=0)\n",
    "- [Documentation video (YouTube)](https://youtu.be/afolWC9hfCI?si=sEM4GCfJR_onvcgo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8e98f",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469ea093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib==3.10.6 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.10.6)\n",
      "Requirement already satisfied: librosa==0.9.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.9.2)\n",
      "Requirement already satisfied: sounddevice==0.5.3 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: setuptools==80.9.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (80.9.0)\n",
      "Requirement already satisfied: scipy==1.16.3 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.16.3)\n",
      "Requirement already satisfied: ipython==9.8.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (9.8.0)\n",
      "Requirement already satisfied: tensorflow-macos>=2.16.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-metal==1.1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.1.0)\n",
      "Requirement already satisfied: keras==3.12.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (3.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from matplotlib==3.10.6->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.4.3)\n",
      "Requirement already satisfied: numba>=0.45.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.63.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from sounddevice==0.5.3->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipython==9.8.0->-r requirements.txt (line 8)) (4.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow-metal==1.1.0->-r requirements.txt (line 10)) (0.45.1)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow-metal==1.1.0->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: absl-py in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (2.3.1)\n",
      "Requirement already satisfied: rich in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (14.2.0)\n",
      "Requirement already satisfied: namex in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (3.15.1)\n",
      "Requirement already satisfied: optree in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (0.18.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from keras==3.12.0->-r requirements.txt (line 11)) (0.3.2)\n",
      "Requirement already satisfied: wcwidth in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython==9.8.0->-r requirements.txt (line 8)) (0.2.14)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.8.16)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 1)) (6.5.1)\n",
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2.16.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (0.37.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: pycparser in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice==0.5.3->-r requirements.txt (line 5)) (2.23)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from jedi>=0.18.1->ipython==9.8.0->-r requirements.txt (line 8)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 1)) (4.5.1)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from numba>=0.45.1->librosa==0.9.2->-r requirements.txt (line 4)) (0.46.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from pexpect>4.3->ipython==9.8.0->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython==9.8.0->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython==9.8.0->-r requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: pure_eval in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython==9.8.0->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.16.2->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from rich->keras==3.12.0->-r requirements.txt (line 11)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.12.0->-r requirements.txt (line 11)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %pip install -r requirements.txt\n",
    "except:\n",
    "    print(\"Could not run pip to install requirements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bddc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os, sys\n",
    "    import numpy as np, librosa\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import Audio, display\n",
    "except ImportError:\n",
    "    print(\"To run the code in its entirity, please install the requirements.txt file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52193421",
   "metadata": {},
   "source": [
    "## Clone the GitHub Repository \n",
    "\n",
    "If this does not work, please drop the smart-home-kws directory in this script's current directory for a full demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640f75be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'smart-home-kws' already exists and is not an empty directory.\n",
      "\n",
      "Successfully cloned the repository.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    !git clone https://github.com/Eclo19/smart-home-kws\n",
    "    print(\"\\nSuccessfully cloned the repository.\")\n",
    "    sys.path.append(\"smart-home-kws\")\n",
    "except Exception:\n",
    "    print(\"Could not clone repository. Please add the 'smart-home-kws' directory to this working space.\")\n",
    "    print(\"   --> After adding 'smart-home-kws', please run sys.path.append('smart-home-kws')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116c248",
   "metadata": {},
   "source": [
    "## Data Gathering and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\KNOWN ERROR REACHED: You are likely getting this error because you re-ran this cell after calling sanitize_vanilla_dataset().\n",
      "This function writes wav files in place of any other formats (such as .m4a here).\n",
      "The rest of the notebook should still run normally if variables were note restarted.\n",
      "If variables were restarted, please delete the current 'smart-home-kws' directory and re-download it/re-clone it.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericoliviera/miniforge3/envs/mltest2/lib/python3.11/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw_m4a_audio_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m       \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThe rest of the notebook should still run normally if variables were note restarted.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m       \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIf variables were restarted, please delete the current \u001b[39m\u001b[33m'\u001b[39m\u001b[33msmart-home-kws\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory and re-download it/re-clone it.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRaw audio File info:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Audio file format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_m4a_path.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Audio Shape       = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mraw_m4a_audio_data\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Sample rate       = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Audio dtype       = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_m4a_audio_data.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDisplaying audio file:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m display(Audio(raw_m4a_audio_data, rate=sr))\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_m4a_audio_data' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 1) Show a raw data point (label is the first word; 'blue' here) ---\n",
    "\n",
    "raw_m4a_path = 'smart-home-kws/Toy_Dataset/Full/blue_eric_03_full.m4a'\n",
    "try:\n",
    "      raw_m4a_audio_data, sr = librosa.load(raw_m4a_path, sr=None)\n",
    "except:\n",
    "      print(\"\\n\\nKNOWN ERROR REACHED: You are likely getting this error because you re-ran this cell after calling sanitize_vanilla_dataset().\")\n",
    "      print(\"This function writes wav files in place of any other formats (such as .m4a here).\")\n",
    "      print(\"The rest of the notebook should still run normally if variables were note restarted.\")\n",
    "      print(\"If variables were restarted, please delete the current 'smart-home-kws' directory and re-download it/re-clone it.\")\n",
    "      print(\"This is why you are likely seeing 'NameError: name 'raw_m4a_audio_data' is not defined' here.\\n\\n\")\n",
    "\n",
    "print(\"Raw audio File info:\\n\"\n",
    "      f\"    Audio file format: {raw_m4a_path.split('.')[-1]}\\n\"\n",
    "      f\"    Audio Shape       = {raw_m4a_audio_data.shape}\\n\"\n",
    "      f\"    Sample rate       = {sr}\\n\"\n",
    "      f\"    Audio dtype       = {raw_m4a_audio_data.dtype}\\n\")\n",
    "print(\"Displaying audio file:\\n\")\n",
    "display(Audio(raw_m4a_audio_data, rate=sr))\n",
    "\n",
    "t = np.arange(len(raw_m4a_audio_data)) / sr\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(t, raw_m4a_audio_data, color='black')\n",
    "plt.title(\"Example Waveform: blue_eric_03_full.m4a\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (float32)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4082916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forcing project standards to the raw recording. This includes:\\n\"\n",
    "        \"    - forcing our sample rate of 22.05 kHz\\n\"\n",
    "        \"    - forcing wav format\\n\"\n",
    "        \"    - summing to mono if stereo\\n\"\n",
    "        \"    - ensuring dtype is float32\\n\"\n",
    "        \"    - normalizing\\n\")\n",
    "\n",
    "try:\n",
    "    import data_augmentation\n",
    "except ImportError:\n",
    "    print(\"Could not import Python script from the cloned Repository.\")\n",
    "else:\n",
    "    data_augmentation.VANILLA_DATA_PATH = \"smart-home-kws/Toy_Dataset/Full\"\n",
    "    data_augmentation.sanitize_vanilla_dataset()\n",
    "\n",
    "    audio_path = \"smart-home-kws/Toy_Dataset/Full/blue_eric_03_full.wav\"\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    print(\"Sanitized audio File info:\\n\\n\"\n",
    "            f\"    Audio file format: {audio_path.split('.')[-1]}\\n\"\n",
    "            f\"    Audio Shape       = {audio_data.shape}\\n\"\n",
    "            f\"    Sample rate       = {sr}\\n\"\n",
    "            f\"    Audio dtype       = {audio_data.dtype}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Show how sanitized files are chopped ---\n",
    "\n",
    "try:\n",
    "    import file_chopper\n",
    "except ImportError:\n",
    "    print(\"Could not import Python script from the cloned Repository.\")\n",
    "\n",
    "print(\n",
    "    \"The default parameters should be a good fit, but the user must choose\\n\"\n",
    "    \"their threshold and window_length to adapt to each recording.\\n\\n\"\n",
    "    \"NOTE: A prompt will show up to check/reset chopping parameters.\\n\"\n",
    "    \"If you do not wish to write the chops, press 'esc' in each prompt\\n\"\n",
    "    \"(this will throw an error).\\n\"\n",
    "    \"For demo purposes, press 1 for both prompts and write the chops.\\n\"\n",
    "    \"\\nThe parameters are already set, so simply press '1' for both prompts to generate data.\\n\"\n",
    ")\n",
    "\n",
    "file_chopper.FULL_DATA_PATH = \"smart-home-kws/Toy_Dataset/Full\"\n",
    "file_chopper.CHOPPED_DIR    = \"smart-home-kws/Toy_Dataset/Live_chops\"\n",
    "file_chopper.parse(wait=int(22050*0.15), duration=int(22050*0.45))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_chops_path = \"smart-home-kws/Toy_Dataset/Live_chops\"\n",
    "if os.path.isdir(live_chops_path):\n",
    "    data_augmentation.VANILLA_DATA_PATH = live_chops_path\n",
    "    data_augmentation.sanitize_vanilla_dataset()\n",
    "\n",
    "    print(\"Now displaying the first chop:\")\n",
    "    blue_1_path = os.path.join(live_chops_path, \"blue_eric_03_01.wav\")\n",
    "    audio_data, sr = librosa.load(blue_1_path, sr=None)\n",
    "    display(Audio(audio_data, rate=sr))\n",
    "\n",
    "    t = np.arange(len(audio_data)) / sr\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t, audio_data, color=\"black\")\n",
    "    plt.title(\"Example Waveform: blue_eric_03_01.wav\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (float32)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Live chops directory not found. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb180c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Show data augmentation transformations ---\n",
    "print(\n",
    "    \"We split the data with wrapper.split_dataset(), but it is too costly to run here.\\n\"\n",
    "    \"Instead, we show how we expanded the training set:\\n\"\n",
    "    \"  - Filtering: taps designed with pyfda, convolved via scipy\\n\"\n",
    "    \"  - Pitch-shifting: librosa.effects\\n\\n\"\n",
    "    \"Now displaying all audio transformations applied to a training chop:\\n\"\n",
    ")\n",
    "transforms = [\n",
    "    (\"Original chop:\",       lambda x: x),\n",
    "    (\"Low-passed:\",          data_augmentation.low_pass),\n",
    "    (\"High-passed:\",         data_augmentation.high_pass),\n",
    "    (\"Band-passed:\",         data_augmentation.band_pass),\n",
    "    (\"Pitched Up:\",          data_augmentation.pitch_up),\n",
    "    (\"Pitched Down:\",        data_augmentation.pitch_down),\n",
    "    (\"Added red noise:\",     data_augmentation.add_noise),\n",
    "]\n",
    "for desc, fn in transforms:\n",
    "    print(desc)\n",
    "    transformed_audio_data = fn(audio_data)\n",
    "    display(Audio(transformed_audio_data, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce729b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Show Feature Extraction ---\n",
    "print(\n",
    "    \"\\nWe build json feature dictionaries for train/val/test using \"\n",
    "    \"feature_extraction.build_feature_dict(). This calls MFCC extraction and \"\n",
    "    \"label vectorization for each point, writing (flat_mfccs, vec_label) to JSON.\"\n",
    ")\n",
    "try:\n",
    "    import feature_extraction, wrapper\n",
    "except ImportError:\n",
    "    print(\"Could not import Python script from the cloned Repository.\")\n",
    "else:\n",
    "    wrapper.force_standard_size(dirname=live_chops_path, size=39243)\n",
    "\n",
    "    audio_data, sr = librosa.load(blue_1_path, sr=None)\n",
    "    print(f\"Data length = {len(audio_data)}\")\n",
    "    mfccs = feature_extraction.extract_mfccs(audio_data=audio_data)\n",
    "    print(f\"\\nMFCCs shape: {mfccs.shape}\")\n",
    "\n",
    "    l = os.path.basename(blue_1_path).split(\"_\")[0]\n",
    "    vec_label = feature_extraction.vectorize_label(label=l)\n",
    "    print(f\"\\nParsed label = {l}, vec label:\\n{vec_label}\")\n",
    "\n",
    "    mfcc_masked = np.ma.masked_equal(mfccs, 0.0)\n",
    "    cmap = plt.cm.viridis.copy()\n",
    "    cmap.set_bad(\"white\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    im = plt.imshow(mfcc_masked, aspect=\"auto\", origin=\"lower\", cmap=cmap)\n",
    "    plt.title(\"Model's input - MFCC Visualization (Zero-padding shown in white)\")\n",
    "    plt.xlabel(\"Time frames\")\n",
    "    plt.ylabel(\"MFCC coefficient index\")\n",
    "    plt.colorbar(im, label=\"MFCC value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33203431",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9c3a5",
   "metadata": {},
   "source": [
    "The full script for training the model is available and at https://colab.research.google.com/drive/1zg0SPHg8Gk4uLPPREuo5_4F8gLJBUEz0?usp=sharing. We show some basics of how the model was trained and some test data inferencing as well, but showing the full training would require too much time and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37361ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf, keras\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Could not import tensorflow. This is likely due to an environment/OS mismatch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Loading the data ---\n",
    "print(\n",
    "    \"Our processed data is stored as a json feature dictionary of (x, y) tuples.\\n\"\n",
    "    \"We load it with wrapper.wrapper(dirname, augmented=False).\\n\\n\"\n",
    "    \"When loading the augmented training, validation, and test data, the shapes should be:\\n\\n\"\n",
    "    \"Train's x shape: (15561, 4928)\\n\"\n",
    "    \"Train's y shape: (15561, 9)\\n\\n\"\n",
    "    \"Val's x shape:   (485, 4928)\\n\"\n",
    "    \"Val's y shape:   (485, 9)\\n\\n\"\n",
    "    \"Test's x shape:  (473, 4928)\\n\"\n",
    "    \"Test's y shape:  (473, 9)\\n\\n\"\n",
    "    \"The split is roughly 70% train, 15% test, 15% validation (for the vanilla set).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Defining the Model ---\n",
    "L = tf.keras.layers\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 154, 1))\n",
    "\n",
    "# Block 1\n",
    "x = L.Conv2D(64, (4, 4), activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = L.BatchNormalization()(x); x = L.MaxPool2D(2)(x); x = L.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 2\n",
    "x = L.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = L.BatchNormalization()(x); x = L.MaxPool2D(2)(x); x = L.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 3\n",
    "x = L.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = L.BatchNormalization()(x); x = L.MaxPool2D(2)(x); x = L.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "# Global pooling + Dense\n",
    "x = L.GlobalAveragePooling2D()(x)\n",
    "x = L.Dense(128, activation=\"relu\")(x)\n",
    "x = L.Dropout(0.3)(x)\n",
    "\n",
    "#Outputs\n",
    "outputs = L.Dense(9, activation=\"softmax\")(x)\n",
    "cnn = tf.keras.Model(inputs, outputs)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Training sketch (no data provided to avoid computation) ---\n",
    "\n",
    "# Hyperparameters\n",
    "lr, batch_size, epochs = 1e-3, 50, 20\n",
    "stop_patience, lr_patience, lr_factor = 5, 2, 0.5\n",
    "\n",
    "# Compile model\n",
    "cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "C = tf.keras.callbacks\n",
    "early_stop = C.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=stop_patience,\n",
    "    restore_best_weights=True, verbose=1\n",
    ")\n",
    "reduce_lr = C.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=lr_factor,\n",
    "    patience=lr_patience, min_lr=1e-6, verbose=1\n",
    ")\n",
    "checkpoint = C.ModelCheckpoint(\n",
    "    filepath=\"best_cnn_run4_padrobust-epoch{epoch:02d}-\"\n",
    "             \"valloss{val_loss:.4f}-valacc{val_accuracy:.4f}.keras\",\n",
    "    monitor=\"val_loss\", save_best_only=True, verbose=1\n",
    ")\n",
    "# Sketch of the training loop (disabled)\n",
    "if False:\n",
    "    x = y = xv = yv = None\n",
    "    history = cnn.fit(\n",
    "        x, y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "        validation_data=(xv, yv),\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f494d44",
   "metadata": {},
   "source": [
    "## Real-Time Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fd7cd",
   "metadata": {},
   "source": [
    "Real-time inference works in the following way:\n",
    "\n",
    "1) Record a 4s long buffer when the button is pressed\n",
    "2) Extract an input window of length 39243 (model's input size in samples) based on DSP techniques (Leaky integrator's maximum will determine the midpoint of the input window)\n",
    "3) Normalize and force zeros around the midpoint of the window, to mimic zero-padded training data\n",
    "4) Extract zeroed-out window's MFCCs and feed it to the model\n",
    "5) Get a prediction\n",
    "6) Take some action based on the prediction in the embedded device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Run Inference on Test Data ---\n",
    "\n",
    "test_path  = \"smart-home-kws/Toy_Dataset/Test Data\"\n",
    "MODEL_PATH = \"smart-home-kws/Models/best_cnn_run4_padrobust-epoch15-valloss0.0025-valacc1.0000.keras\"\n",
    "N_MFCC, T_FRAMES = feature_extraction.N_MFCC, feature_extraction.T_FRAMES\n",
    "\n",
    "# Random test point + true label\n",
    "test_points    = [f for f in os.listdir(test_path) if f.lower().endswith((\".wav\", \".m4a\", \".flac\", \".ogg\"))]\n",
    "test_filename  = np.random.choice(test_points)\n",
    "test_data_path = os.path.join(test_path, test_filename)\n",
    "true_label_str = test_filename.split(\"_\")[0]\n",
    "print(f\"Random test file: {test_filename}\")\n",
    "print(f\"True label parsed from filename: {true_label_str}\")\n",
    "\n",
    "# Label mapping dim --> string\n",
    "label_mapping = {\n",
    "    \"red\": 0, \"green\": 1, \"blue\": 2, \"white\": 3, \"off\": 4,\n",
    "    \"time\": 5, \"temperature\": 6, \"unknown\": 7, \"noise\": 8\n",
    "}\n",
    "idx_to_label = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Audio + MFCCs\n",
    "audio_data, sr = librosa.load(test_data_path)\n",
    "display(Audio(audio_data, rate=sr))\n",
    "mfccs = feature_extraction.extract_mfccs(audio_data=audio_data)\n",
    "print(\"MFCCs shape:\", mfccs.shape)\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nLoading model from: {MODEL_PATH}\")\n",
    "model = keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"Loaded model successfully.\\n\")\n",
    "\n",
    "# Prepare input + predict\n",
    "input_matrix = mfccs.reshape(1, N_MFCC, T_FRAMES, 1).astype(np.float32)\n",
    "print(\"input_matrix shape:\", input_matrix.shape, \"dtype:\", input_matrix.dtype)\n",
    "y_pred    = model.predict(input_matrix, verbose=0)[0]\n",
    "pred_idx  = int(np.argmax(y_pred))\n",
    "pred_label = idx_to_label[pred_idx]\n",
    "\n",
    "print(\"\\nInference Result\")\n",
    "print(f\"    - True label      : {true_label_str}\")\n",
    "print(f\"    - Predicted label : {pred_label}\")\n",
    "print(\"    - Model output (softmax probabilities):\")\n",
    "print(y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bf8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Run Inference on Pre-Recorded Window, Simulating Embedded Behavior ---\n",
    "\n",
    "audio_data, sr = librosa.load(\"smart-home-kws/Toy_Dataset/Window/full_window.wav\", sr=None)\n",
    "audio_data = audio_data.astype(np.float32)\n",
    "audio_data /= np.max(np.abs(audio_data))\n",
    "print(\"\\nInput window test:\"); display(Audio(audio_data, rate=sr))\n",
    "\n",
    "try:\n",
    "    import inference_test as it\n",
    "except ImportError:\n",
    "    print(\"Could not import Python script from the cloned Repository.\")\n",
    "else:\n",
    "    # Extract best window + zero-out edges\n",
    "    input_window        = it.plot_signal_and_loudest_window_leaky(audio_data, sr=sr, tau_ms=200)\n",
    "    input_window_zeroed = it.zero_out(input_window)\n",
    "\n",
    "    # Plot pipeline\n",
    "    t = np.arange(len(input_window)) / sr\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "    ax1.plot(t, input_window);        ax1.set_title(\"Extracted Input Window\"); ax1.set_ylabel(\"Amplitude\")\n",
    "    ax2.plot(t, input_window_zeroed); ax2.set_title(\"Zeroed-Out Extracted Input Window\")\n",
    "    ax2.set_xlabel(\"Time(s)\");        ax2.set_ylabel(\"Amplitude\")\n",
    "    fig.tight_layout(); plt.show()\n",
    "\n",
    "    print(\"\\nCleaned input window:\"); display(Audio(input_window_zeroed, rate=sr))\n",
    "\n",
    "    # Extract features + run inference\n",
    "    mfccs = feature_extraction.extract_mfccs(audio_data=input_window_zeroed)\n",
    "    print(\"MFCCs shape:\", mfccs.shape)\n",
    "    input_matrix = mfccs.reshape(1, N_MFCC, T_FRAMES, 1).astype(np.float32)\n",
    "    y_pred = model.predict(input_matrix, verbose=0)[0]\n",
    "    pred_idx  = int(np.argmax(y_pred))\n",
    "    pred_label = idx_to_label[pred_idx]\n",
    "\n",
    "    print(\"\\n===== Inference Result =====\")\n",
    "    print(f\"    - Predicted label : {pred_label}\\n\"\n",
    "          f\"    - Model output (softmax probabilities):\\n{y_pred.ravel()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltest2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
